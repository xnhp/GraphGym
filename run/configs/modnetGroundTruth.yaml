out_dir: results_modnet
metric_best: modularity
device: cpu
dataset:
  format: modnet  # load a pre-generated kHSBM graph for each repetition
  interpretation: single
  name: pregen-modnet-graph  # does not matter here
  dir: associative_n=400_k=5  # from where to load pre-generated graphs from
  task: node
  task_type: community
  num_communities: 5  # see also config.dataset.sbm_c
  transductive: True  # can only generate embeddings for nodes seen during training phase
  split: [1.0] # only trivial split
  augment_feature: ['node_onehot_full']
  augment_feature_dims: [1] # always needs to have same length, see feature_augment.py
  augment_feature_repr: original
  # use default values for SBM generation for now
train:
  mode: groundtruth  # or run_alg
  # batch_size: 32
  eval_period: 100
  ckpt_period: 100
model:
  type: gnn
  loss_fun: soft_modularity_bipartite
  collapse_lam: 0.0
  # edge_decoding: dot
  # graph_pooling: add
gnn:
  layers_pre_mp: 0  # like in modnet
  layers_mp: 2  # like in modnet
  layers_post_mp: 1  # like in modnet
  # dim_inner: 50  # like in modnet
  layer_type: generalconv
  stage_type: stack
  batchnorm: False
  act: prelu
  dropout: 0.0 # like in modnet
  agg: add  # ?? what are the options?
  normalize_adj: False # ??
optim:
  optimizer: adam # ??
  base_lr: 0.1  # like in modnet
  max_epoch: 300  # modnet: 150